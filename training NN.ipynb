{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d35729f3-8bce-4d54-9557-00b1d381106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import activations\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "print(pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ad6c64f6-3e4c-4442-8168-749617b3d8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"rawpoints/Train82.csv\",low_memory=False)\n",
    "tdf = pd.read_csv(\"rawpoints/Test82.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0488810-8119-4f99-b656-80413d8f53b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna() #removing nan values\n",
    "tdf = tdf.dropna() #removing nan values\n",
    "# tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "00b5dc0a-fed0-4720-8823-0b9f4d821b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()\n",
    "train_x = df.loc[:, df.columns != 'ImgPath' ]\n",
    "train_y = np.array(train_x.loc[:,train_x.columns == 'label'])\n",
    "train_x = np.array(train_x.loc[:, train_x.columns != 'label' ])\n",
    "# print(train_x)\n",
    "\n",
    "# print(train_x)\n",
    "\n",
    "# df.head()\n",
    "test_x = tdf.loc[:, tdf.columns != 'ImgPath' ]\n",
    "test_y = np.array(test_x.loc[:,test_x.columns == 'label'])\n",
    "test_x = np.array(test_x.loc[:, test_x.columns != 'label' ])\n",
    "# print(train_x)\n",
    "\n",
    "# print(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "17c8e592-c5cc-4af7-be91-3c4ebe3e68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_x)\n",
    "train_x = scaler.transform(train_x)\n",
    "# for i in range(len(train_y)):\n",
    "    # train_y[i][0]=int(train_y[i][0])\n",
    "# len(train_x[0])\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(test_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8f3c4a13-6752-4e91-b4a8-efbb6f8ae5ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61402961 -0.50192187 -0.71025018 ...  0.21223679  0.91107768\n",
      "   0.7551523 ]\n",
      " [ 0.05822381 -0.03669392  0.15267182 ... -0.26612688 -0.26990379\n",
      "   0.08987409]\n",
      " [ 0.44289044  0.45277137  0.42190437 ...  0.08575432  0.70882581\n",
      "   0.49558071]\n",
      " ...\n",
      " [ 0.14393422  0.18932109  0.12659374 ...  0.03518295  0.3935659\n",
      "   0.08443708]\n",
      " [ 0.05399048  0.1655146   0.01195941 ... -0.50988237  0.10165657\n",
      "  -0.4880183 ]\n",
      " [-0.40073809 -0.45736434 -0.36404861 ...  0.65596734  0.18484645\n",
      "   0.44014383]]\n"
     ]
    }
   ],
   "source": [
    "train_y_lst = []\n",
    "for i in range(len(train_x)):\n",
    "    lt = np.zeros((82,), dtype=int)\n",
    "    lt[train_y[i]] = 1\n",
    "    train_y_lst.append(lt)\n",
    "train_y_lst = np.array(train_y_lst)\n",
    "train_y_lst\n",
    "\n",
    "test_y_lst = []\n",
    "for i in range(len(test_x)):\n",
    "    lt = np.zeros((82,), dtype=int)\n",
    "    lt[test_y[i]] = 1\n",
    "    test_y_lst.append(lt)\n",
    "test_y_lst = np.array(test_y_lst)\n",
    "print(test_x)\n",
    "# test_y_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3867550f-e449-48d3-b833-c0af1d713edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.0520 - loss: 4.0759 - val_accuracy: 0.1680 - val_loss: 3.1364\n",
      "Epoch 2/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1780 - loss: 3.0848 - val_accuracy: 0.3412 - val_loss: 2.4843\n",
      "Epoch 3/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.2848 - loss: 2.5708 - val_accuracy: 0.4112 - val_loss: 2.1510\n",
      "Epoch 4/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3855 - loss: 2.2150 - val_accuracy: 0.4961 - val_loss: 1.8705\n",
      "Epoch 5/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4557 - loss: 1.9861 - val_accuracy: 0.5771 - val_loss: 1.6759\n",
      "Epoch 6/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5162 - loss: 1.7659 - val_accuracy: 0.5746 - val_loss: 1.6184\n",
      "Epoch 7/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5260 - loss: 1.7201 - val_accuracy: 0.5967 - val_loss: 1.5579\n",
      "Epoch 8/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5570 - loss: 1.5986 - val_accuracy: 0.6073 - val_loss: 1.4805\n",
      "Epoch 9/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5818 - loss: 1.5182 - val_accuracy: 0.6354 - val_loss: 1.4712\n",
      "Epoch 10/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5930 - loss: 1.4563 - val_accuracy: 0.6669 - val_loss: 1.3665\n",
      "Epoch 11/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6119 - loss: 1.4069 - val_accuracy: 0.6728 - val_loss: 1.3249\n",
      "Epoch 12/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6147 - loss: 1.3628 - val_accuracy: 0.6692 - val_loss: 1.3118\n",
      "Epoch 13/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.6325 - loss: 1.3118 - val_accuracy: 0.6877 - val_loss: 1.2826\n",
      "Epoch 14/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6396 - loss: 1.2870 - val_accuracy: 0.6892 - val_loss: 1.2580\n",
      "Epoch 15/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6540 - loss: 1.2379 - val_accuracy: 0.7116 - val_loss: 1.2133\n",
      "Epoch 16/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6625 - loss: 1.2331 - val_accuracy: 0.7030 - val_loss: 1.2491\n",
      "Epoch 17/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6770 - loss: 1.2076 - val_accuracy: 0.7190 - val_loss: 1.2157\n",
      "Epoch 18/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6866 - loss: 1.1420 - val_accuracy: 0.7190 - val_loss: 1.1662\n",
      "Epoch 19/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6915 - loss: 1.1254 - val_accuracy: 0.7415 - val_loss: 1.1735\n",
      "Epoch 20/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7005 - loss: 1.0874 - val_accuracy: 0.7332 - val_loss: 1.1882\n",
      "Epoch 21/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6959 - loss: 1.1115 - val_accuracy: 0.7426 - val_loss: 1.1737\n",
      "Epoch 22/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7032 - loss: 1.0839 - val_accuracy: 0.7484 - val_loss: 1.1502\n",
      "Epoch 23/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7170 - loss: 1.0506 - val_accuracy: 0.7558 - val_loss: 1.1372\n",
      "Epoch 24/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7179 - loss: 1.0386 - val_accuracy: 0.7413 - val_loss: 1.1466\n",
      "Epoch 25/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7135 - loss: 1.0368 - val_accuracy: 0.7598 - val_loss: 1.0979\n",
      "Epoch 26/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7262 - loss: 0.9905 - val_accuracy: 0.7509 - val_loss: 1.0838\n",
      "Epoch 27/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7250 - loss: 1.0191 - val_accuracy: 0.7592 - val_loss: 1.1256\n",
      "Epoch 28/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.9727 - val_accuracy: 0.7622 - val_loss: 1.1147\n",
      "Epoch 29/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7297 - loss: 0.9914 - val_accuracy: 0.7598 - val_loss: 1.0970\n",
      "Epoch 30/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7395 - loss: 0.9421 - val_accuracy: 0.7843 - val_loss: 1.0751\n",
      "Epoch 31/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7403 - loss: 0.9551 - val_accuracy: 0.7700 - val_loss: 1.0907\n",
      "Epoch 32/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7532 - loss: 0.9134 - val_accuracy: 0.7781 - val_loss: 1.0642\n",
      "Epoch 33/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7468 - loss: 0.9136 - val_accuracy: 0.7777 - val_loss: 1.0396\n",
      "Epoch 34/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7490 - loss: 0.9077 - val_accuracy: 0.7820 - val_loss: 1.0642\n",
      "Epoch 35/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.8760 - val_accuracy: 0.7920 - val_loss: 1.0547\n",
      "Epoch 36/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7595 - loss: 0.8641 - val_accuracy: 0.7771 - val_loss: 1.0605\n",
      "Epoch 37/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 0.8736 - val_accuracy: 0.7890 - val_loss: 1.0772\n",
      "Epoch 38/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7640 - loss: 0.8723 - val_accuracy: 0.7962 - val_loss: 1.0365\n",
      "Epoch 39/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7690 - loss: 0.8758 - val_accuracy: 0.7903 - val_loss: 1.0546\n",
      "Epoch 40/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7689 - loss: 0.8238 - val_accuracy: 0.8026 - val_loss: 1.0262\n",
      "Epoch 41/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7684 - loss: 0.8475 - val_accuracy: 0.7988 - val_loss: 1.0585\n",
      "Epoch 42/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7725 - loss: 0.8157 - val_accuracy: 0.7962 - val_loss: 1.0493\n",
      "Epoch 43/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.8214 - val_accuracy: 0.8022 - val_loss: 1.0156\n",
      "Epoch 44/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.8419 - val_accuracy: 0.7969 - val_loss: 1.0161\n",
      "Epoch 45/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7866 - loss: 0.8052 - val_accuracy: 0.8060 - val_loss: 1.0233\n",
      "Epoch 46/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7852 - loss: 0.7869 - val_accuracy: 0.8079 - val_loss: 1.0419\n",
      "Epoch 47/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7804 - loss: 0.8221 - val_accuracy: 0.8026 - val_loss: 1.0170\n",
      "Epoch 48/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7799 - loss: 0.7950 - val_accuracy: 0.8058 - val_loss: 1.0444\n",
      "Epoch 49/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7848 - loss: 0.8053 - val_accuracy: 0.8073 - val_loss: 1.0197\n",
      "Epoch 50/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7859 - loss: 0.7812 - val_accuracy: 0.8026 - val_loss: 1.0574\n",
      "Epoch 51/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7822 - loss: 0.8028 - val_accuracy: 0.7971 - val_loss: 1.0437\n",
      "Epoch 52/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7937 - loss: 0.7679 - val_accuracy: 0.8103 - val_loss: 0.9783\n",
      "Epoch 53/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7935 - loss: 0.7608 - val_accuracy: 0.8064 - val_loss: 0.9906\n",
      "Epoch 54/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7980 - loss: 0.7395 - val_accuracy: 0.8147 - val_loss: 0.9986\n",
      "Epoch 55/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7949 - loss: 0.7639 - val_accuracy: 0.8122 - val_loss: 0.9985\n",
      "Epoch 56/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7992 - loss: 0.7542 - val_accuracy: 0.8164 - val_loss: 1.0075\n",
      "Epoch 57/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7960 - loss: 0.7304 - val_accuracy: 0.8098 - val_loss: 1.0526\n",
      "Epoch 58/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8020 - loss: 0.7484 - val_accuracy: 0.8154 - val_loss: 0.9567\n",
      "Epoch 59/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8053 - loss: 0.7176 - val_accuracy: 0.8028 - val_loss: 1.0068\n",
      "Epoch 60/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8025 - loss: 0.7273 - val_accuracy: 0.8139 - val_loss: 1.0095\n",
      "Epoch 61/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8048 - loss: 0.7206 - val_accuracy: 0.8192 - val_loss: 0.9663\n",
      "Epoch 62/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8070 - loss: 0.7273 - val_accuracy: 0.8209 - val_loss: 0.9754\n",
      "Epoch 63/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8082 - loss: 0.7173 - val_accuracy: 0.8213 - val_loss: 0.9428\n",
      "Epoch 64/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8075 - loss: 0.7112 - val_accuracy: 0.8175 - val_loss: 0.9447\n",
      "Epoch 65/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 0.6874 - val_accuracy: 0.8217 - val_loss: 0.9731\n",
      "Epoch 66/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8142 - loss: 0.7012 - val_accuracy: 0.8158 - val_loss: 0.9597\n",
      "Epoch 67/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8067 - loss: 0.6975 - val_accuracy: 0.8277 - val_loss: 0.9477\n",
      "Epoch 68/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8177 - loss: 0.6884 - val_accuracy: 0.8183 - val_loss: 0.9852\n",
      "Epoch 69/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8181 - loss: 0.6569 - val_accuracy: 0.8271 - val_loss: 0.9354\n",
      "Epoch 70/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8129 - loss: 0.6718 - val_accuracy: 0.8271 - val_loss: 0.9376\n",
      "Epoch 71/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8180 - loss: 0.6613 - val_accuracy: 0.8341 - val_loss: 0.9442\n",
      "Epoch 72/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 0.6784 - val_accuracy: 0.8326 - val_loss: 0.9181\n",
      "Epoch 73/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8197 - loss: 0.6646 - val_accuracy: 0.8222 - val_loss: 0.9486\n",
      "Epoch 74/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8199 - loss: 0.6801 - val_accuracy: 0.8181 - val_loss: 0.9563\n",
      "Epoch 75/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8178 - loss: 0.6910 - val_accuracy: 0.8200 - val_loss: 0.9760\n",
      "Epoch 76/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.6806 - val_accuracy: 0.8268 - val_loss: 0.9508\n",
      "Epoch 77/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8343 - loss: 0.6316 - val_accuracy: 0.8268 - val_loss: 0.9745\n",
      "Epoch 78/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.6468 - val_accuracy: 0.8358 - val_loss: 0.9387\n",
      "Epoch 79/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.6470 - val_accuracy: 0.8313 - val_loss: 0.9346\n",
      "Epoch 80/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8292 - loss: 0.6466 - val_accuracy: 0.8279 - val_loss: 0.9453\n",
      "Epoch 81/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8292 - loss: 0.6391 - val_accuracy: 0.8226 - val_loss: 0.9366\n",
      "Epoch 82/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8264 - loss: 0.6589 - val_accuracy: 0.8343 - val_loss: 0.9534\n",
      "Epoch 83/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.6193 - val_accuracy: 0.8290 - val_loss: 0.9278\n",
      "Epoch 84/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8280 - loss: 0.6353 - val_accuracy: 0.8326 - val_loss: 0.9339\n",
      "Epoch 85/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.6376 - val_accuracy: 0.8241 - val_loss: 0.9477\n",
      "Epoch 86/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8276 - loss: 0.6219 - val_accuracy: 0.8383 - val_loss: 0.8764\n",
      "Epoch 87/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8296 - loss: 0.6230 - val_accuracy: 0.8302 - val_loss: 0.9267\n",
      "Epoch 88/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8342 - loss: 0.6191 - val_accuracy: 0.8275 - val_loss: 0.9227\n",
      "Epoch 89/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.6176 - val_accuracy: 0.8375 - val_loss: 0.8819\n",
      "Epoch 90/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8364 - loss: 0.5955 - val_accuracy: 0.8377 - val_loss: 0.9009\n",
      "Epoch 91/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8405 - loss: 0.6196 - val_accuracy: 0.8388 - val_loss: 0.9138\n",
      "Epoch 92/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8441 - loss: 0.5656 - val_accuracy: 0.8371 - val_loss: 0.9296\n",
      "Epoch 93/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.6261 - val_accuracy: 0.8341 - val_loss: 0.9229\n",
      "Epoch 94/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.6198 - val_accuracy: 0.8402 - val_loss: 0.9252\n",
      "Epoch 95/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8399 - loss: 0.5883 - val_accuracy: 0.8349 - val_loss: 0.9058\n",
      "Epoch 96/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8383 - loss: 0.6001 - val_accuracy: 0.8317 - val_loss: 0.9246\n",
      "Epoch 97/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.5859 - val_accuracy: 0.8317 - val_loss: 0.9442\n",
      "Epoch 98/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8421 - loss: 0.5955 - val_accuracy: 0.8332 - val_loss: 0.9380\n",
      "Epoch 99/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.5983 - val_accuracy: 0.8309 - val_loss: 0.9307\n",
      "Epoch 100/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8425 - loss: 0.5948 - val_accuracy: 0.8383 - val_loss: 0.9162\n",
      "Epoch 101/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.6000 - val_accuracy: 0.8407 - val_loss: 0.8766\n",
      "Epoch 102/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.5990 - val_accuracy: 0.8400 - val_loss: 0.8978\n",
      "Epoch 103/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.6113 - val_accuracy: 0.8413 - val_loss: 0.8877\n",
      "Epoch 104/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8376 - loss: 0.5932 - val_accuracy: 0.8396 - val_loss: 0.9262\n",
      "Epoch 105/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8482 - loss: 0.5821 - val_accuracy: 0.8411 - val_loss: 0.8905\n",
      "Epoch 106/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8412 - loss: 0.5780 - val_accuracy: 0.8409 - val_loss: 0.9377\n",
      "Epoch 107/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8368 - loss: 0.6092 - val_accuracy: 0.8443 - val_loss: 0.9163\n",
      "Epoch 108/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.5749 - val_accuracy: 0.8428 - val_loss: 0.8940\n",
      "Epoch 109/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.6010 - val_accuracy: 0.8394 - val_loss: 0.9230\n",
      "Epoch 110/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8496 - loss: 0.5643 - val_accuracy: 0.8454 - val_loss: 0.8989\n",
      "Epoch 111/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 0.5815 - val_accuracy: 0.8432 - val_loss: 0.8838\n",
      "Epoch 112/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.5874 - val_accuracy: 0.8464 - val_loss: 0.8759\n",
      "Epoch 113/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8475 - loss: 0.5752 - val_accuracy: 0.8490 - val_loss: 0.9097\n",
      "Epoch 114/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8564 - loss: 0.5257 - val_accuracy: 0.8481 - val_loss: 0.8859\n",
      "Epoch 115/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8541 - loss: 0.5588 - val_accuracy: 0.8454 - val_loss: 0.8944\n",
      "Epoch 116/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8420 - loss: 0.5670 - val_accuracy: 0.8454 - val_loss: 0.9062\n",
      "Epoch 117/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.6068 - val_accuracy: 0.8511 - val_loss: 0.8423\n",
      "Epoch 118/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.5760 - val_accuracy: 0.8405 - val_loss: 0.8997\n",
      "Epoch 119/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8480 - loss: 0.5792 - val_accuracy: 0.8407 - val_loss: 0.9449\n",
      "Epoch 120/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8451 - loss: 0.5893 - val_accuracy: 0.8464 - val_loss: 0.9048\n",
      "Epoch 121/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8563 - loss: 0.5378 - val_accuracy: 0.8392 - val_loss: 0.9337\n",
      "Epoch 122/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8490 - loss: 0.5791 - val_accuracy: 0.8505 - val_loss: 0.9020\n",
      "Epoch 123/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.5550 - val_accuracy: 0.8460 - val_loss: 0.8794\n",
      "Epoch 124/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.5451 - val_accuracy: 0.8471 - val_loss: 0.8604\n",
      "Epoch 125/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8453 - loss: 0.5825 - val_accuracy: 0.8454 - val_loss: 0.9049\n",
      "Epoch 126/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8634 - loss: 0.5020 - val_accuracy: 0.8437 - val_loss: 0.8827\n",
      "Epoch 127/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8596 - loss: 0.5458 - val_accuracy: 0.8447 - val_loss: 0.8785\n",
      "Epoch 128/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8434 - loss: 0.6010 - val_accuracy: 0.8407 - val_loss: 0.9182\n",
      "Epoch 129/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8525 - loss: 0.5513 - val_accuracy: 0.8462 - val_loss: 0.9111\n",
      "Epoch 130/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.5483 - val_accuracy: 0.8488 - val_loss: 0.8475\n",
      "Epoch 131/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8510 - loss: 0.5582 - val_accuracy: 0.8445 - val_loss: 0.8692\n",
      "Epoch 132/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8529 - loss: 0.5518 - val_accuracy: 0.8347 - val_loss: 0.9026\n",
      "Epoch 133/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8477 - loss: 0.5898 - val_accuracy: 0.8419 - val_loss: 0.8966\n",
      "Epoch 134/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.5294 - val_accuracy: 0.8479 - val_loss: 0.9132\n",
      "Epoch 135/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8640 - loss: 0.5094 - val_accuracy: 0.8475 - val_loss: 0.9179\n",
      "Epoch 136/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.5394 - val_accuracy: 0.8434 - val_loss: 0.9014\n",
      "Epoch 137/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8609 - loss: 0.5325 - val_accuracy: 0.8473 - val_loss: 0.8771\n",
      "Epoch 138/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8518 - loss: 0.5372 - val_accuracy: 0.8492 - val_loss: 0.8547\n",
      "Epoch 139/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8549 - loss: 0.5335 - val_accuracy: 0.8481 - val_loss: 0.8795\n",
      "Epoch 140/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8580 - loss: 0.5443 - val_accuracy: 0.8458 - val_loss: 0.8856\n",
      "Epoch 141/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8601 - loss: 0.5171 - val_accuracy: 0.8475 - val_loss: 0.9092\n",
      "Epoch 142/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.5369 - val_accuracy: 0.8494 - val_loss: 0.9090\n",
      "Epoch 143/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8631 - loss: 0.5169 - val_accuracy: 0.8568 - val_loss: 0.8642\n",
      "Epoch 144/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 0.5073 - val_accuracy: 0.8526 - val_loss: 0.8713\n",
      "Epoch 145/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.5412 - val_accuracy: 0.8573 - val_loss: 0.8876\n",
      "Epoch 146/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.5185 - val_accuracy: 0.8494 - val_loss: 0.8982\n",
      "Epoch 147/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8551 - loss: 0.5582 - val_accuracy: 0.8536 - val_loss: 0.8598\n",
      "Epoch 148/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8638 - loss: 0.5234 - val_accuracy: 0.8473 - val_loss: 0.9047\n",
      "Epoch 149/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.4901 - val_accuracy: 0.8539 - val_loss: 0.8705\n",
      "Epoch 150/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8627 - loss: 0.5344 - val_accuracy: 0.8445 - val_loss: 0.9184\n",
      "Epoch 151/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8554 - loss: 0.5288 - val_accuracy: 0.8492 - val_loss: 0.8873\n",
      "Epoch 152/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.5209 - val_accuracy: 0.8505 - val_loss: 0.9199\n",
      "Epoch 153/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.5194 - val_accuracy: 0.8466 - val_loss: 0.9366\n",
      "Epoch 154/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8618 - loss: 0.5100 - val_accuracy: 0.8477 - val_loss: 0.9332\n",
      "Epoch 155/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8602 - loss: 0.5233 - val_accuracy: 0.8511 - val_loss: 0.9191\n",
      "Epoch 156/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8619 - loss: 0.5082 - val_accuracy: 0.8524 - val_loss: 0.9054\n",
      "Epoch 157/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.4820 - val_accuracy: 0.8468 - val_loss: 0.8990\n",
      "Epoch 158/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.4900 - val_accuracy: 0.8519 - val_loss: 0.8977\n",
      "Epoch 159/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8614 - loss: 0.5370 - val_accuracy: 0.8466 - val_loss: 0.9001\n",
      "Epoch 160/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8624 - loss: 0.5315 - val_accuracy: 0.8492 - val_loss: 0.9076\n",
      "Epoch 161/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8576 - loss: 0.5489 - val_accuracy: 0.8492 - val_loss: 0.9247\n",
      "Epoch 162/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.4851 - val_accuracy: 0.8494 - val_loss: 0.8657\n",
      "Epoch 163/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.5084 - val_accuracy: 0.8422 - val_loss: 0.9321\n",
      "Epoch 164/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8646 - loss: 0.4948 - val_accuracy: 0.8500 - val_loss: 0.8776\n",
      "Epoch 165/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8635 - loss: 0.5028 - val_accuracy: 0.8513 - val_loss: 0.8921\n",
      "Epoch 166/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.4933 - val_accuracy: 0.8500 - val_loss: 0.9075\n",
      "Epoch 167/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8717 - loss: 0.4848 - val_accuracy: 0.8598 - val_loss: 0.8774\n",
      "Epoch 168/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.4958 - val_accuracy: 0.8532 - val_loss: 0.9078\n",
      "Epoch 169/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8682 - loss: 0.5124 - val_accuracy: 0.8573 - val_loss: 0.8409\n",
      "Epoch 170/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8623 - loss: 0.5030 - val_accuracy: 0.8541 - val_loss: 0.8913\n",
      "Epoch 171/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.4954 - val_accuracy: 0.8513 - val_loss: 0.8865\n",
      "Epoch 172/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8669 - loss: 0.5099 - val_accuracy: 0.8545 - val_loss: 0.8868\n",
      "Epoch 173/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8715 - loss: 0.4732 - val_accuracy: 0.8490 - val_loss: 0.8815\n",
      "Epoch 174/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8704 - loss: 0.4939 - val_accuracy: 0.8443 - val_loss: 0.9277\n",
      "Epoch 175/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.4845 - val_accuracy: 0.8522 - val_loss: 0.9076\n",
      "Epoch 176/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.4896 - val_accuracy: 0.8526 - val_loss: 0.9301\n",
      "Epoch 177/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8714 - loss: 0.4939 - val_accuracy: 0.8483 - val_loss: 0.9054\n",
      "Epoch 178/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 0.5106 - val_accuracy: 0.8545 - val_loss: 0.8704\n",
      "Epoch 179/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.4817 - val_accuracy: 0.8547 - val_loss: 0.8978\n",
      "Epoch 180/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8702 - loss: 0.5067 - val_accuracy: 0.8517 - val_loss: 0.8895\n",
      "Epoch 181/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8722 - loss: 0.4710 - val_accuracy: 0.8541 - val_loss: 0.8757\n",
      "Epoch 182/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8766 - loss: 0.4755 - val_accuracy: 0.8496 - val_loss: 0.8807\n",
      "Epoch 183/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8700 - loss: 0.4759 - val_accuracy: 0.8530 - val_loss: 0.8685\n",
      "Epoch 184/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8741 - loss: 0.4593 - val_accuracy: 0.8473 - val_loss: 0.8570\n",
      "Epoch 185/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.4819 - val_accuracy: 0.8581 - val_loss: 0.8817\n",
      "Epoch 186/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.4637 - val_accuracy: 0.8519 - val_loss: 0.8994\n",
      "Epoch 187/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8712 - loss: 0.4907 - val_accuracy: 0.8539 - val_loss: 0.8581\n",
      "Epoch 188/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8728 - loss: 0.4611 - val_accuracy: 0.8558 - val_loss: 0.8757\n",
      "Epoch 189/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8778 - loss: 0.4591 - val_accuracy: 0.8481 - val_loss: 0.8819\n",
      "Epoch 190/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.4705 - val_accuracy: 0.8483 - val_loss: 0.8683\n",
      "Epoch 191/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8731 - loss: 0.5024 - val_accuracy: 0.8566 - val_loss: 0.8867\n",
      "Epoch 192/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.4702 - val_accuracy: 0.8549 - val_loss: 0.8949\n",
      "Epoch 193/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8697 - loss: 0.5116 - val_accuracy: 0.8547 - val_loss: 0.8962\n",
      "Epoch 194/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8772 - loss: 0.4665 - val_accuracy: 0.8522 - val_loss: 0.8872\n",
      "Epoch 195/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8788 - loss: 0.4465 - val_accuracy: 0.8583 - val_loss: 0.9053\n",
      "Epoch 196/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.4558 - val_accuracy: 0.8564 - val_loss: 0.8705\n",
      "Epoch 197/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8747 - loss: 0.4821 - val_accuracy: 0.8517 - val_loss: 0.8907\n",
      "Epoch 198/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8811 - loss: 0.4485 - val_accuracy: 0.8562 - val_loss: 0.8895\n",
      "Epoch 199/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8781 - loss: 0.4624 - val_accuracy: 0.8492 - val_loss: 0.9356\n",
      "Epoch 200/200\n",
      "\u001b[1m762/762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8803 - loss: 0.4607 - val_accuracy: 0.8543 - val_loss: 0.8865\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.optimizers.legacy.Adam()\n",
    "model = tf.keras.models.Sequential([\n",
    "    Dense(200, activation = 'relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(150, activation = 'relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(100, activation = 'relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(82, activation = 'relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(20, activation = 'relu'),\n",
    "    Dense(6, activation = 'relu'),\n",
    "    Dense(82, activation = 'softmax')\n",
    "    ])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_x,train_y_lst, validation_data=(test_x, test_y_lst),epochs = 200,batch_size = 16,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e26ea6-4989-45bf-b75c-759ce71a5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss Curves')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure()\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy Curves')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be610b-4e69-4d13-b4b4-600a9d4781f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(train_x, train_y_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c61c6fd-9dce-4a02-b883-ccc92e803bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_x, test_y_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b6057-ab89-4afd-ae1c-7b833786b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073aa1d-f0e2-43e4-bd31-ed2480eb2e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330b48c-7d77-4949-b68b-46bc758185e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_y = []\n",
    "for i in range(len(y_pred)):\n",
    "    ind = -1;\n",
    "    max = -1;\n",
    "    for j in range(len(y_pred[i])):\n",
    "        if(y_pred[i][j]>max):\n",
    "            max = y_pred[i][j]\n",
    "            ind = j;\n",
    "    act_y.append(ind)\n",
    "act_y = np.array(act_y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd887d7-d3c5-4dbf-ae86-7dff7621c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "act_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8fc63-c21b-4d09-ae8a-79efd0deef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(test_y,act_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351858cd-dea6-442a-b6e9-bfa653a76ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a077b3-c822-47dd-98fc-0763e53952a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e51a71-0554-4be6-8ebc-3976fba5f8b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc994e-5627-4927-9254-9a689de03582",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98eeff-328d-47c9-af91-c31f0f17e0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
